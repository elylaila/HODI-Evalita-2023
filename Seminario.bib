
@misc{devlin_bert_2019,
	title = {{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding},
	url = {http://arxiv.org/abs/1810.04805},
	shorttitle = {{BERT}},
	abstract = {We introduce a new language representation model called {BERT}, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), {BERT} is designed to pretrain deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained {BERT} model can be ﬁnetuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial taskspeciﬁc architecture modiﬁcations.},
	number = {{arXiv}:1810.04805},
	publisher = {{arXiv}},
	author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	urldate = {2023-08-28},
	date = {2019-05-24},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1810.04805 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {Devlin et al. - 2019 - BERT Pre-training of Deep Bidirectional Transform.pdf:C\:\\Users\\irene\\Zotero\\storage\\QCN6BVNL\\Devlin et al. - 2019 - BERT Pre-training of Deep Bidirectional Transform.pdf:application/pdf},
}

@article{hochreiter_long_1997,
	title = {Long Short-Term Memory},
	volume = {9},
	issn = {0899-7667},
	url = {https://doi.org/10.1162/neco.1997.9.8.1735},
	doi = {10.1162/neco.1997.9.8.1735},
	abstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory ({LSTM}). Truncating the gradient where this does not do harm, {LSTM} can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. {LSTM} is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, {LSTM} leads to many more successful runs, and learns much faster. {LSTM} also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},
	pages = {1735--1780},
	number = {8},
	journaltitle = {Neural Computation},
	shortjournal = {Neural Computation},
	author = {Hochreiter, Sepp and Schmidhuber, Jürgen},
	urldate = {2023-08-28},
	date = {1997-11-15},
	file = {2604.pdf:C\:\\Users\\irene\\Zotero\\storage\\636YHCJM\\2604.pdf:application/pdf},
}

@inproceedings{vaswani_attention_2017,
	title = {Attention is All you Need},
	volume = {30},
	url = {https://proceedings.neurips.cc/paper_files/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html},
	abstract = {The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 {BLEU} {onEnglish}-to-German translation, improving over the existing best ensemble result by over 1 {BLEU}. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 {BLEU}, achieving a {BLEU} score of 41.1.},
	booktitle = {Advances in Neural Information Processing Systems},
	publisher = {Curran Associates, Inc.},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Łukasz and Polosukhin, Illia},
	urldate = {2023-09-23},
	date = {2017},
	file = {Full Text PDF:C\:\\Users\\irene\\Zotero\\storage\\FJK67755\\Vaswani et al. - 2017 - Attention is All you Need.pdf:application/pdf},
}

@misc{sanh_distilbert_2020,
	title = {{DistilBERT}, a distilled version of {BERT}: smaller, faster, cheaper and lighter},
	url = {http://arxiv.org/abs/1910.01108},
	doi = {10.48550/arXiv.1910.01108},
	shorttitle = {{DistilBERT}, a distilled version of {BERT}},
	abstract = {As Transfer Learning from large-scale pre-trained models becomes more prevalent in Natural Language Processing ({NLP}), operating these large models in on-the-edge and/or under constrained computational training or inference budgets remains challenging. In this work, we propose a method to pre-train a smaller general-purpose language representation model, called {DistilBERT}, which can then be fine-tuned with good performances on a wide range of tasks like its larger counterparts. While most prior work investigated the use of distillation for building task-specific models, we leverage knowledge distillation during the pre-training phase and show that it is possible to reduce the size of a {BERT} model by 40\%, while retaining 97\% of its language understanding capabilities and being 60\% faster. To leverage the inductive biases learned by larger models during pre-training, we introduce a triple loss combining language modeling, distillation and cosine-distance losses. Our smaller, faster and lighter model is cheaper to pre-train and we demonstrate its capabilities for on-device computations in a proof-of-concept experiment and a comparative on-device study.},
	number = {{arXiv}:1910.01108},
	publisher = {{arXiv}},
	author = {Sanh, Victor and Debut, Lysandre and Chaumond, Julien and Wolf, Thomas},
	urldate = {2023-09-23},
	date = {2020-02-29},
	eprinttype = {arxiv},
	eprint = {1910.01108 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {Sanh et al. - 2020 - DistilBERT, a distilled version of BERT smaller, .pdf:C\:\\Users\\irene\\Zotero\\storage\\I7YEA6IY\\Sanh et al. - 2020 - DistilBERT, a distilled version of BERT smaller, .pdf:application/pdf},
}

@article{mathew_hatexplain_2021,
	title = {{HateXplain}: A Benchmark Dataset for Explainable Hate Speech Detection},
	volume = {35},
	rights = {Copyright (c) 2021 Association for the Advancement of Artificial Intelligence},
	issn = {2374-3468},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/17745},
	doi = {10.1609/aaai.v35i17.17745},
	shorttitle = {{HateXplain}},
	abstract = {Hate speech is a challenging issue plaguing the online social media. While better models for hate speech detection are continuously being developed, there is little research on the bias and interpretability aspects of hate speech. In this paper, we introduce {HateXplain}, the first benchmark hate speech dataset covering multiple aspects of the issue. Each post in our dataset is annotated from three different perspectives: the basic, commonly used 3-class classification (i.e., hate, offensive or normal), the target community (i.e., the community that has been the victim of hate speech/offensive speech in the post), and the rationales, i.e., the portions of the post on which their labelling decision (as hate, offensive or normal) is based. We utilize existing state-of-the-art models and observe that even models that perform very well in classification do not score high on explainability metrics like model plausibility and faithfulness. We also observe that models, which utilize the human rationales for training, perform better in reducing unintended bias towards target communities. We have made our code and dataset public for other researchers.},
	pages = {14867--14875},
	number = {17},
	journaltitle = {Proceedings of the {AAAI} Conference on Artificial Intelligence},
	author = {Mathew, Binny and Saha, Punyajoy and Yimam, Seid Muhie and Biemann, Chris and Goyal, Pawan and Mukherjee, Animesh},
	urldate = {2023-09-23},
	date = {2021-05-18},
	langid = {english},
	note = {Number: 17},
	keywords = {Other Social Impact},
	file = {Mathew et al. - 2021 - HateXplain A Benchmark Dataset for Explainable Ha.pdf:C\:\\Users\\irene\\Zotero\\storage\\AVBE6EKD\\17745-Article Text-21239-1-2-20210518.pdf:application/pdf},
}

@misc{chaudhary_countering_2021,
	title = {Countering Online Hate Speech: An {NLP} Perspective},
	url = {http://arxiv.org/abs/2109.02941},
	doi = {10.48550/arXiv.2109.02941},
	shorttitle = {Countering Online Hate Speech},
	abstract = {Online hate speech has caught everyone's attention from the news related to the {COVID}-19 pandemic, {US} elections, and worldwide protests. Online toxicity - an umbrella term for online hateful behavior, manifests itself in forms such as online hate speech. Hate speech is a deliberate attack directed towards an individual or a group motivated by the targeted entity's identity or opinions. The rising mass communication through social media further exacerbates the harmful consequences of online hate speech. While there has been significant research on hate-speech identification using Natural Language Processing ({NLP}), the work on utilizing {NLP} for prevention and intervention of online hate speech lacks relatively. This paper presents a holistic conceptual framework on hate-speech {NLP} countering methods along with a thorough survey on the current progress of {NLP} for countering online hate speech. It classifies the countering techniques based on their time of action, and identifies potential future research areas on this topic.},
	number = {{arXiv}:2109.02941},
	publisher = {{arXiv}},
	author = {Chaudhary, Mudit and Saxena, Chandni and Meng, Helen},
	urldate = {2023-09-23},
	date = {2021-09-07},
	eprinttype = {arxiv},
	eprint = {2109.02941 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, notion},
	file = {arXiv Fulltext PDF:C\:\\Users\\irene\\Zotero\\storage\\8TLWBG8J\\Chaudhary et al. - 2021 - Countering Online Hate Speech An NLP Perspective.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\irene\\Zotero\\storage\\5Z4ZMXPT\\2109.html:text/html},
}

@misc{chakravarthi_dataset_2021,
	title = {Dataset for Identification of Homophobia and Transophobia in Multilingual {YouTube} Comments},
	url = {http://arxiv.org/abs/2109.00227},
	abstract = {The increased proliferation of abusive content on social media platforms has a negative impact on online users. The dread, dislike, discomfort, or mistrust of lesbian, gay, transgender or bisexual persons is defined as homophobia/transphobia. Homophobic/transphobic speech is a type of offensive language that may be summarized as hate speech directed toward {LGBT}+ people, and it has been a growing concern in recent years. Online homophobia/transphobia is a severe societal problem that can make online platforms poisonous and unwelcome to {LGBT}+ people while also attempting to eliminate equality, diversity, and inclusion. We provide a new hierarchical taxonomy for online homophobia and transphobia, as well as an expert-labelled dataset that will allow homophobic/transphobic content to be automatically identified. We educated annotators and supplied them with comprehensive annotation rules because this is a sensitive issue, and we previously discovered that untrained crowdsourcing annotators struggle with diagnosing homophobia due to cultural and other prejudices. The dataset comprises 15,141 annotated multilingual comments. This paper describes the process of building the dataset, qualitative analysis of data, and inter-annotator agreement. In addition, we create baseline models for the dataset. To the best of our knowledge, our dataset is the first such dataset created. Warning: This paper contains explicit statements of homophobia, transphobia, stereotypes which may be distressing to some readers.},
	number = {{arXiv}:2109.00227},
	publisher = {{arXiv}},
	author = {Chakravarthi, Bharathi Raja and Priyadharshini, Ruba and Ponnusamy, Rahul and Kumaresan, Prasanna Kumar and Sampath, Kayalvizhi and Thenmozhi, Durairaj and Thangasamy, Sathiyaraj and Nallathambi, Rajendran and {McCrae}, John Phillip},
	urldate = {2023-09-23},
	date = {2021-09-01},
	eprinttype = {arxiv},
	eprint = {2109.00227 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv.org Snapshot:C\:\\Users\\irene\\Zotero\\storage\\NGPPSXGL\\2109.html:text/html;Full Text PDF:C\:\\Users\\irene\\Zotero\\storage\\IRGKMECJ\\Chakravarthi et al. - 2021 - Dataset for Identification of Homophobia and Trans.pdf:application/pdf},
}

@inproceedings{nozza_exposing_2021,
	location = {Online},
	title = {Exposing the limits of Zero-shot Cross-lingual Hate Speech Detection},
	url = {https://aclanthology.org/2021.acl-short.114},
	doi = {10.18653/v1/2021.acl-short.114},
	abstract = {Reducing and counter-acting hate speech on Social Media is a significant concern. Most of the proposed automatic methods are conducted exclusively on English and very few consistently labeled, non-English resources have been proposed. Learning to detect hate speech on English and transferring to unseen languages seems an immediate solution. This work is the first to shed light on the limits of this zero-shot, cross-lingual transfer learning framework for hate speech detection. We use benchmark data sets in English, Italian, and Spanish to detect hate speech towards immigrants and women. Investigating post-hoc explanations of the model, we discover that non-hateful, language-specific taboo interjections are misinterpreted as signals of hate speech. Our findings demonstrate that zero-shot, cross-lingual models cannot be used as they are, but need to be carefully designed.},
	eventtitle = {{ACL}-{IJCNLP} 2021},
	pages = {907--914},
	booktitle = {Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)},
	publisher = {Association for Computational Linguistics},
	author = {Nozza, Debora},
	urldate = {2023-09-23},
	date = {2021-08},
	keywords = {notion},
	file = {Full Text PDF:C\:\\Users\\irene\\Zotero\\storage\\H8PE6K96\\Nozza - 2021 - Exposing the limits of Zero-shot Cross-lingual Hat.pdf:application/pdf},
}

@inproceedings{attanasio_entropy-based_2022,
	location = {Dublin, Ireland},
	title = {Entropy-based Attention Regularization Frees Unintended Bias Mitigation from Lists},
	url = {https://aclanthology.org/2022.findings-acl.88},
	doi = {10.18653/v1/2022.findings-acl.88},
	abstract = {Natural Language Processing ({NLP}) models risk overfitting to specific terms in the training data, thereby reducing their performance, fairness, and generalizability. E.g., neural hate speech detection models are strongly influenced by identity terms like gay, or women, resulting in false positives, severe unintended bias, and lower performance. Most mitigation techniques use lists of identity terms or samples from the target domain during training. However, this approach requires a-priori knowledge and introduces further bias if important terms are neglected. Instead, we propose a knowledge-free Entropy-based Attention Regularization ({EAR}) to discourage overfitting to training-specific terms. An additional objective function penalizes tokens with low self-attention entropy. We fine-tune {BERT} via {EAR}: the resulting model matches or exceeds state-of-the-art performance for hate speech classification and bias metrics on three benchmark corpora in English and Italian.{EAR} also reveals overfitting terms, i.e., terms most likely to induce bias, to help identify their effect on the model, task, and predictions.},
	eventtitle = {Findings 2022},
	pages = {1105--1119},
	booktitle = {Findings of the Association for Computational Linguistics: {ACL} 2022},
	publisher = {Association for Computational Linguistics},
	author = {Attanasio, Giuseppe and Nozza, Debora and Hovy, Dirk and Baralis, Elena},
	urldate = {2023-09-23},
	date = {2022-05},
	keywords = {notion},
	file = {Full Text PDF:C\:\\Users\\irene\\Zotero\\storage\\HFW9D3H9\\Attanasio et al. - 2022 - Entropy-based Attention Regularization Frees Unint.pdf:application/pdf},
}

@inproceedings{jin_towards_2019,
	title = {Towards Hierarchical Importance Attribution: Explaining Compositional Semantics for Neural Sequence Models},
	url = {https://openreview.net/forum?id=BkxRRkSKwr},
	shorttitle = {Towards Hierarchical Importance Attribution},
	abstract = {The impressive performance of neural networks on natural language processing tasks attributes to their ability to model complicated word and phrase compositions. To explain how the model handles semantic compositions, we study hierarchical explanation of neural network predictions. We identify non-additivity and context independent importance attributions within hierarchies as two desirable properties for highlighting word and phrase compositions. We show some prior efforts on hierarchical explanations, e.g. contextual decomposition, do not satisfy the desired properties mathematically, leading to inconsistent explanation quality in different models. In this paper, we start by proposing a formal and general way to quantify the importance of each word and phrase. Following the formulation, we propose Sampling and Contextual Decomposition ({SCD}) algorithm and Sampling and Occlusion ({SOC}) algorithm. Human and metrics evaluation on both {LSTM} models and {BERT} Transformer models on multiple datasets show that our algorithms outperform prior hierarchical explanation algorithms. Our algorithms help to visualize semantic composition captured by models, extract classification rules and improve human trust of models.},
	eventtitle = {International Conference on Learning Representations},
	author = {Jin, Xisen and Wei, Zhongyu and Du, Junyi and Xue, Xiangyang and Ren, Xiang},
	urldate = {2023-10-02},
	date = {2019-09-25},
	file = {Jin et al. - 2019 - Towards Hierarchical Importance Attribution Explaining Compositional Semantics for Neural Sequence Models.pdf:C\:\\Users\\irene\\Zotero\\storage\\PCWIUCXP\\Jin et al. - 2019 - Towards Hierarchical Importance Attribution Explaining Compositional Semantics for Neural Sequence Models.pdf:application/pdf},
}

@article{fortuna_survey_2018,
	title = {A Survey on Automatic Detection of Hate Speech in Text},
	volume = {51},
	issn = {0360-0300},
	url = {https://dl.acm.org/doi/10.1145/3232676},
	doi = {10.1145/3232676},
	abstract = {The scientific study of hate speech, from a computer science point of view, is recent. This survey organizes and describes the current state of the field, providing a structured overview of previous approaches, including core algorithms, methods, and main features used. This work also discusses the complexity of the concept of hate speech, defined in many platforms and contexts, and provides a unifying definition. This area has an unquestionable potential for societal impact, particularly in online communities and digital media platforms. The development and systematization of shared resources, such as guidelines, annotated datasets in multiple languages, and algorithms, is a crucial step in advancing the automatic detection of hate speech.},
	pages = {85:1--85:30},
	number = {4},
	journaltitle = {{ACM} Computing Surveys},
	shortjournal = {{ACM} Comput. Surv.},
	author = {Fortuna, Paula and Nunes, Sérgio},
	urldate = {2023-10-02},
	date = {2018-07-31},
	keywords = {Hate speech, literature review, natural language processing, opinion mining, text mining, notion},
	file = {Fortuna and Nunes - 2018 - A Survey on Automatic Detection of Hate Speech in Text.pdf:C\:\\Users\\irene\\Zotero\\storage\\7T6ACEHW\\Fortuna and Nunes - 2018 - A Survey on Automatic Detection of Hate Speech in Text.pdf:application/pdf},
}

@inproceedings{dixon_measuring_2018,
	location = {New Orleans {LA} {USA}},
	title = {Measuring and Mitigating Unintended Bias in Text Classification},
	isbn = {978-1-4503-6012-8},
	url = {https://dl.acm.org/doi/10.1145/3278721.3278729},
	doi = {10.1145/3278721.3278729},
	eventtitle = {{AIES} '18: {AAAI}/{ACM} Conference on {AI}, Ethics, and Society},
	pages = {67--73},
	booktitle = {Proceedings of the 2018 {AAAI}/{ACM} Conference on {AI}, Ethics, and Society},
	publisher = {{ACM}},
	author = {Dixon, Lucas and Li, John and Sorensen, Jeffrey and Thain, Nithum and Vasserman, Lucy},
	urldate = {2023-10-14},
	date = {2018-12-27},
	langid = {english},
	file = {Full Text PDF:C\:\\Users\\irene\\Zotero\\storage\\ANH6DM99\\Dixon et al. - 2018 - Measuring and Mitigating Unintended Bias in Text C.pdf:application/pdf},
}

@inproceedings{park_one-step_2017,
	location = {Vancouver, {BC}, Canada},
	title = {One-step and Two-step Classification for Abusive Language Detection on Twitter},
	url = {https://aclanthology.org/W17-3006},
	doi = {10.18653/v1/W17-3006},
	abstract = {Automatic abusive language detection is a difficult but important task for online social media. Our research explores a two-step approach of performing classification on abusive language and then classifying into specific types and compares it with one-step approach of doing one multi-class classification for detecting sexist and racist languages. With a public English Twitter corpus of 20 thousand tweets in the type of sexism and racism, our approach shows a promising performance of 0.827 F-measure by using {HybridCNN} in one-step and 0.824 F-measure by using logistic regression in two-steps.},
	eventtitle = {{ALW} 2017},
	pages = {41--45},
	publisher = {Association for Computational Linguistics},
	author = {Park, Ji Ho and Fung, Pascale},
	urldate = {2023-10-20},
	date = {2017-08},
	file = {Park and Fung - 2017 - One-step and Two-step Classification for Abusive Language Detection on Twitter.pdf:C\:\\Users\\irene\\Zotero\\storage\\GU6F3PLN\\Park and Fung - 2017 - One-step and Two-step Classification for Abusive Language Detection on Twitter.pdf:application/pdf},
}

@inproceedings{badjatiya_deep_2017,
	location = {Republic and Canton of Geneva, {CHE}},
	title = {Deep Learning for Hate Speech Detection in Tweets},
	isbn = {978-1-4503-4914-7},
	url = {https://dl.acm.org/doi/10.1145/3041021.3054223},
	doi = {10.1145/3041021.3054223},
	series = {{WWW} '17 Companion},
	abstract = {Hate speech detection on Twitter is critical for applications like controversial event extraction, building {AI} chatterbots, content recommendation, and sentiment analysis. We define this task as being able to classify a tweet as racist, sexist or neither. The complexity of the natural language constructs makes this task very challenging. We perform extensive experiments with multiple deep learning architectures to learn semantic word embeddings to handle this complexity. Our experiments on a benchmark dataset of 16K annotated tweets show that such deep learning methods outperform state-of-the-art char/word n-gram methods by {\textasciitilde}18 F1 points.},
	pages = {759--760},
	publisher = {International World Wide Web Conferences Steering Committee},
	author = {Badjatiya, Pinkesh and Gupta, Shashank and Gupta, Manish and Varma, Vasudeva},
	urldate = {2023-10-20},
	date = {2017-04-03},
	keywords = {cnn, deep learning applications, hate speech detection, lstm, twitter},
	file = {Badjatiya et al. - 2017 - Deep Learning for Hate Speech Detection in Tweets.pdf:C\:\\Users\\irene\\Zotero\\storage\\X5QGAZQ6\\Badjatiya et al. - 2017 - Deep Learning for Hate Speech Detection in Tweets.pdf:application/pdf},
}

@inproceedings{zampieri_semeval-2020_2020,
	location = {Barcelona (online)},
	title = {{SemEval}-2020 Task 12: Multilingual Offensive Language Identification in Social Media ({OffensEval} 2020)},
	url = {https://aclanthology.org/2020.semeval-1.188},
	doi = {10.18653/v1/2020.semeval-1.188},
	shorttitle = {{SemEval}-2020 Task 12},
	abstract = {We present the results and the main findings of {SemEval}-2020 Task 12 on Multilingual Offensive Language Identification in Social Media ({OffensEval}-2020). The task included three subtasks corresponding to the hierarchical taxonomy of the {OLID} schema from {OffensEval}-2019, and it was offered in five languages: Arabic, Danish, English, Greek, and Turkish. {OffensEval}-2020 was one of the most popular tasks at {SemEval}-2020, attracting a large number of participants across all subtasks and languages: a total of 528 teams signed up to participate in the task, 145 teams submitted official runs on the test data, and 70 teams submitted system description papers.},
	eventtitle = {{SemEval} 2020},
	pages = {1425--1447},
	publisher = {International Committee for Computational Linguistics},
	author = {Zampieri, Marcos and Nakov, Preslav and Rosenthal, Sara and Atanasova, Pepa and Karadzhov, Georgi and Mubarak, Hamdy and Derczynski, Leon and Pitenis, Zeses and Çöltekin, Çağrı},
	urldate = {2023-10-20},
	date = {2020-12},
	file = {Zampieri et al. - 2020 - SemEval-2020 Task 12 Multilingual Offensive Language Identification in Social Media (OffensEval 2020).pdf:C\:\\Users\\irene\\Zotero\\storage\\VDDAGGCK\\Zampieri et al. - 2020 - SemEval-2020 Task 12 Multilingual Offensive Language Identification in Social Media (OffensEval 2020).pdf:application/pdf},
}

@inproceedings{polignano_alberto_2019,
	title = {{AlBERTo}: Italian {BERT} Language Understanding Model for {NLP} Challenging Tasks Based on Tweets},
	url = {https://www.semanticscholar.org/paper/AlBERTo%3A-Italian-BERT-Language-Understanding-Model-Polignano-Basile/e1e43d6bdb1419e08af833cf4899a460f70da26c},
	shorttitle = {{AlBERTo}},
	abstract = {English. Recent scientific studies on natural language processing ({NLP}) report the outstanding effectiveness observed in the use of context-dependent and task-free language understanding models such as {ELMo}, {GPT}, and {BERT}. Specifically, they have proved to achieve state of the art performance in numerous complex {NLP} tasks such as question answering and sentiment analysis in the English language. Following the great popularity and effectiveness that these models are gaining in the scientific community, we trained a {BERT} language understanding model for the Italian language ({AlBERTo}). In particular, {AlBERTo} is focused on the language used in social networks, specifically on Twitter. To demonstrate its robustness, we evaluated {AlBERTo} on the {EVALITA} 2016 task {SENTIPOLC} ({SENTIment} {POLarity} Classification) obtaining state of the art results in subjectivity, polarity and irony detection on Italian tweets. The pre-trained {AlBERTo} model will be publicly distributed through the {GitHub} platform at the following web address: https://github.com/ marcopoli/{AlBERTo}-it in order to facilitate future research.},
	eventtitle = {Italian Conference on Computational Linguistics},
	author = {Polignano, Marco and Basile, Pierpaolo and Degemmis, M. and Semeraro, G. and Basile, Valerio},
	urldate = {2023-10-20},
	date = {2019},
	file = {Polignano et al. - 2019 - AlBERTo Italian BERT Language Understanding Model for NLP Challenging Tasks Based on Tweets.pdf:C\:\\Users\\irene\\Zotero\\storage\\BBHWXY78\\Polignano et al. - 2019 - AlBERTo Italian BERT Language Understanding Model for NLP Challenging Tasks Based on Tweets.pdf:application/pdf},
}

@article{polignano_alberto_2019-1,
	title = {{AlBERTo}: Modeling Italian Social Media Language with {BERT}},
	volume = {5},
	rights = {https://creativecommons.org/licenses/by-nc-nd/4.0/},
	issn = {2499-4553},
	url = {https://journals.openedition.org/ijcol/472},
	doi = {10.4000/ijcol.472},
	shorttitle = {{AlBERTo}},
	abstract = {Natural Language Processing tasks recently achieved considerable interest and progresses following the development of numerous innovative artificial intelligence models released in recent years. The increase in available computing power has made possible the application of machine learning approaches on a considerable amount of textual data, demonstrating how they can obtain very encouraging results in challenging {NLP} tasks by generalizing the properties of natural language directly from the data. Models such as {ELMo}, {GPT}/{GPT}-2, {BERT}, {ERNIE}, and {RoBERTa} have proved to be extremely useful in {NLP} tasks such as entailment, sentiment analysis, and question answering. The availability of these resources mainly in the English language motivated us towards the realization of {AlBERTo}, a natural language model based on {BERT} and trained on the Italian language. We decided to train {AlBERTo} from scratch on social network language, Twitter in particular, because many of the classic tasks of content analysis are oriented to data extracted from the digital sphere of users. The model was distributed to the community through a repository on {GitHub} and the Transformers library (Wolf et al. 2019) released by the development group huggingface.co. We have evaluated the validity of the model on the classification tasks of sentiment polarity, irony, subjectivity, and hate speech. The specifications of the model, the code developed for training and fine-tuning, and the instructions for using it in a research project are freely available.},
	pages = {11--31},
	number = {2},
	journaltitle = {{IJCoL}. Italian Journal of Computational Linguistics},
	author = {Polignano, Marco and Basile, Valerio and Basile, Pierpaolo and de Gemmis, Marco and Semeraro, Giovanni},
	urldate = {2023-10-20},
	date = {2019-12-01},
	langid = {english},
	file = {Polignano et al. - 2019 - AlBERTo Modeling Italian Social Media Language with BERT.pdf:C\:\\Users\\irene\\Zotero\\storage\\TP2GVBIP\\Polignano et al. - 2019 - AlBERTo Modeling Italian Social Media Language with BERT.pdf:application/pdf},
}

@article{jahan_systematic_2023,
	title = {A systematic review of hate speech automatic detection using natural language processing},
	volume = {546},
	issn = {0925-2312},
	url = {https://www.sciencedirect.com/science/article/pii/S0925231223003557},
	doi = {10.1016/j.neucom.2023.126232},
	abstract = {With the multiplication of social media platforms, which offer anonymity, easy access and online community formation and online debate, the issue of hate speech detection and tracking becomes a growing challenge to society, individual, policy-makers and researchers. Despite efforts for leveraging automatic techniques for automatic detection and monitoring, their performances are still far from satisfactory, which constantly calls for future research on the issue. This paper provides a systematic review of literature in this field, with a focus on natural language processing and deep learning technologies, highlighting the terminology, processing pipeline, core methods employed, with a focal point on deep learning architecture. From a methodological perspective, we adopt {PRISMA} guideline of systematic review of the last 10 years literature from {ACM} Digital Library and Google Scholar. In the sequel, existing surveys, limitations, and future research directions are extensively discussed.},
	pages = {126232},
	journaltitle = {Neurocomputing},
	shortjournal = {Neurocomputing},
	author = {Jahan, Md Saroar and Oussalah, Mourad},
	urldate = {2023-10-15},
	date = {2023-08-14},
	keywords = {notion, Hate speech detection review, {NLP} deep learning review, {PRISMA} hate speech, Systematic review},
	file = {main.pdf:C\:\\Users\\irene\\Zotero\\storage\\3KSGG3UY\\main.pdf:application/pdf},
}

@inreference{nockleby_hate_2000,
	title = {Hate speech},
	booktitle = {Encyclopedia of the American constitution},
	author = {Nockleby, J.T.},
	date = {2000},
}

@report{noauthor_notitle_nodate,
}

@article{noauthor_facebook_2023,
	title = {Facebook to pay \$52m to content moderators over {PTSD}},
	url = {https://www.bbc.com/news/technology-52642633},
	date = {2023-05-13},
}

@article{nozza_hodi_2023,
	title = {{HODI} at {EVALITA} 2023: Overview of the Homotransphobia Detection in Italian Task},
	journaltitle = {Proceedings of the Eighth Evaluation Campaign of Natural Language Processing and Speech Tools for Italian. Final Workshop ({EVALITA} 2023)},
	author = {Nozza, Debora and Cignarella, Alessandra Teresa and Damo, Greta and Caselli, Tommaso and Patti, Viviana},
	date = {2023-09},
}
